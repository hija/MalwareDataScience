{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Malware Detector with strings\n",
    "This malware detector uses the strings-command and the Feature Hasher to create a dataset of malware and benignware. The dataset is split up into training and test and a decision tree and a random forest is trained on the dataset. We make the interesting finding, that there are some features, which are very important for the classification, while the other few thousands are pretty unimportant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  These are the imports we are going to need\n",
    "import subprocess\n",
    "import os\n",
    "import numpy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset using the files in data\n",
    "\n",
    "benignware = os.listdir('data/benignware') # <---------- CHANGE PATH HERE\n",
    "malware = os.listdir('data/malware') # <---------------- CHANGE PATH HERE\n",
    "hasher = FeatureHasher(20000) # We initialize the featurehasher using 20,000 features\n",
    "\n",
    "def extract_strings(filepath):\n",
    "    '''This methods extracts the strings from a file using the strings command in unix os'''\n",
    "    strings = subprocess.Popen(['strings', filepath], stdout=subprocess.PIPE).communicate()[0].decode('utf-8').split('\\n')\n",
    "    return strings\n",
    "\n",
    "benign_strings = [extract_strings('data/benignware/' + benignware[i]) for i in range(len(benignware))] # All strings from benignfiles\n",
    "malware_strings = [extract_strings('data/malware/' + malware[i]) for i in range(len(malware))] # All strings from malwarefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates the dataset by using the FeatureHasher to squash the strings of the file into a featuremap\n",
    "# The code is mostly taken from the malware datascience book\n",
    "\n",
    "benign_features = [] # This list later has all the benign_featuremaps\n",
    "for bs in benign_strings:\n",
    "    # store string features in dictionary form\n",
    "    string_features = {}\n",
    "    for string in bs:\n",
    "        string_features[string] = 1\n",
    "\n",
    "    # hash the features using the hashing trick\n",
    "    hashed_features = hasher.transform([string_features])\n",
    "    # do some data munging to get the feature array\n",
    "    hashed_features = hashed_features.todense()\n",
    "    hashed_features = numpy.asarray(hashed_features)\n",
    "    hashed_features = hashed_features[0]\n",
    "    benign_features.extend([hashed_features])\n",
    "    \n",
    "malware_features = []\n",
    "for ms in malware_strings:\n",
    "    # store string features in dictionary form\n",
    "    string_features = {}\n",
    "    for string in ms:\n",
    "        string_features[string] = 1\n",
    "\n",
    "    # hash the features using the hashing trick\n",
    "    hashed_features = hasher.transform([string_features])\n",
    "    # do some data munging to get the feature array\n",
    "    hashed_features = hashed_features.todense()\n",
    "    hashed_features = numpy.asarray(hashed_features)\n",
    "    hashed_features = hashed_features[0]\n",
    "    malware_features.extend([hashed_features])\n",
    "\n",
    "# Let's create a trainingset\n",
    "X = benign_features + malware_features\n",
    "Y = [1 for _ in range(len(benignware))] + [0 for _ in range(len(malware))]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics:\n",
      "Benign-Files: 991\n",
      "Malware-Files: 428\n"
     ]
    }
   ],
   "source": [
    "# Let's print the statistics (showing that we have more benignware than malware)\n",
    "# It already shows, that we should use some kind of weighting in our algorithms later, to deal with the skewed data\n",
    "\n",
    "print('Statistics:')\n",
    "print('Benign-Files:', len(benignware))\n",
    "print('Malware-Files:', len(malware))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "So after we created our dataset, we finally can start training.\n",
    "First, we start with a randomforest classifier - just like in the book :)\n",
    "But be aware, we use class_weight balanced to deal with the skewed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier on hold-out (70% Train, 30% Test): 0.9812206572769953\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, class_weight=\"balanced\", random_state=42)\n",
    "clf.fit(X_train,Y_train)\n",
    "print('Random Forest Classifier on hold-out (70% Train, 30% Test):', clf.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's come to the point, I find quite interesting. Let's have a look, if one feature is enough to get a good prediction..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier on hold-out with one feature (70% Train, 30% Test): 0.8802816901408451\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, class_weight=\"balanced\", max_features=1, random_state=42)\n",
    "clf.fit(X_train,Y_train)\n",
    "print('Random Forest Classifier on hold-out with one feature (70% Train, 30% Test):', clf.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we only need one feature to have an accuracy of about 90%. Let's go ahead and use only a decision tree. I am pretty confindent, we get good predictions here too - especially, if only one feature is required for a good accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier on hold-out (70% Train, 30% Test): 0.931924882629108\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(class_weight=\"balanced\", random_state=42)\n",
    "clf.fit(X_train, Y_train)\n",
    "print('Decision Tree Classifier on hold-out (70% Train, 30% Test):', clf.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup, so we can see, that one single tree is already very very good. Let's see why this is the case, by looking at the importance of the features. In sum, the importance of all features is 1. Wen can see, that there are two features, which help to distinguish malware / benignware by 50%. That's big and explains, why even a random forest classifier with one feature performs good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21888502861184064, 0.2916072509438595]\n"
     ]
    }
   ],
   "source": [
    "print([x for x in clf.feature_importances_ if x > 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
