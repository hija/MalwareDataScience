{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Malware Detector with strings\n",
    "This malware detector uses the strings-command and the Feature Hasher to create a dataset of malware and benignware. The dataset is split up into training and test and we use a (not so deep) deep neural network to classify. \n",
    "\n",
    "Thus, we solve the task from chapter 9 with deep learning now :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  These are the imports we are going to need\n",
    "import subprocess\n",
    "import os\n",
    "import numpy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset using the files in data\n",
    "\n",
    "benignware = os.listdir('data/benignware') # <---------- CHANGE PATH HERE\n",
    "malware = os.listdir('data/malware') # <---------------- CHANGE PATH HERE\n",
    "hasher = FeatureHasher(1000) # We initialize the featurehasher using 1,000 features\n",
    "\n",
    "def extract_strings(filepath):\n",
    "    '''This methods extracts the strings from a file using the strings command in unix os'''\n",
    "    strings = subprocess.Popen(['strings', filepath], stdout=subprocess.PIPE).communicate()[0].decode('utf-8').split('\\n')\n",
    "    return strings\n",
    "\n",
    "benign_strings = [extract_strings('data/benignware/' + benignware[i]) for i in range(len(benignware))] # All strings from benignfiles\n",
    "malware_strings = [extract_strings('data/malware/' + malware[i]) for i in range(len(malware))] # All strings from malwarefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates the dataset by using the FeatureHasher to squash the strings of the file into a featuremap\n",
    "# The code is mostly taken from the malware datascience book\n",
    "\n",
    "benign_features = [] # This list later has all the benign_featuremaps\n",
    "for bs in benign_strings:\n",
    "    # store string features in dictionary form\n",
    "    string_features = {}\n",
    "    for string in bs:\n",
    "        string_features[string] = 1\n",
    "\n",
    "    # hash the features using the hashing trick\n",
    "    hashed_features = hasher.transform([string_features])\n",
    "    # do some data munging to get the feature array\n",
    "    hashed_features = hashed_features.todense()\n",
    "    hashed_features = numpy.asarray(hashed_features)\n",
    "    hashed_features = hashed_features[0]\n",
    "    benign_features.extend([hashed_features])\n",
    "    \n",
    "malware_features = []\n",
    "for ms in malware_strings:\n",
    "    # store string features in dictionary form\n",
    "    string_features = {}\n",
    "    for string in ms:\n",
    "        string_features[string] = 1\n",
    "\n",
    "    # hash the features using the hashing trick\n",
    "    hashed_features = hasher.transform([string_features])\n",
    "    # do some data munging to get the feature array\n",
    "    hashed_features = hashed_features.todense()\n",
    "    hashed_features = numpy.asarray(hashed_features)\n",
    "    hashed_features = hashed_features[0]\n",
    "    malware_features.extend([hashed_features])\n",
    "\n",
    "# Let's create a trainingset\n",
    "X = benign_features + malware_features\n",
    "Y = [1 for _ in range(len(benignware))] + [0 for _ in range(len(malware))]\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics:\n",
      "Benign-Files: 991\n",
      "Malware-Files: 428\n"
     ]
    }
   ],
   "source": [
    "# Let's print the statistics (showing that we have more benignware than malware)\n",
    "# It already shows, that we should use some kind of weighting in our algorithms later, to deal with the skewed data\n",
    "\n",
    "print('Statistics:')\n",
    "print('Benign-Files:', len(benignware))\n",
    "print('Malware-Files:', len(malware))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "So after we created our dataset, we finally can start training.\n",
    "Firstly, we create new numpy arrays to be used by keras. We then define our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainN = numpy.array(X_train)\n",
    "Y_trainN = numpy.array(Y_train)\n",
    "X_testN  = numpy.array(X_test)\n",
    "Y_testN  = numpy.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "993/993 [==============================] - 0s 234us/step - loss: 0.6076 - acc: 0.7593\n",
      "Epoch 2/10\n",
      "993/993 [==============================] - 0s 62us/step - loss: 0.3291 - acc: 0.9053\n",
      "Epoch 3/10\n",
      "993/993 [==============================] - 0s 68us/step - loss: 0.1958 - acc: 0.9486\n",
      "Epoch 4/10\n",
      "993/993 [==============================] - 0s 51us/step - loss: 0.1247 - acc: 0.9688\n",
      "Epoch 5/10\n",
      "993/993 [==============================] - 0s 58us/step - loss: 0.0750 - acc: 0.9869\n",
      "Epoch 6/10\n",
      "993/993 [==============================] - 0s 54us/step - loss: 0.0456 - acc: 0.9960\n",
      "Epoch 7/10\n",
      "993/993 [==============================] - 0s 68us/step - loss: 0.0276 - acc: 0.9970\n",
      "Epoch 8/10\n",
      "993/993 [==============================] - 0s 62us/step - loss: 0.0172 - acc: 0.9970\n",
      "Epoch 9/10\n",
      "993/993 [==============================] - 0s 64us/step - loss: 0.0108 - acc: 0.9980\n",
      "Epoch 10/10\n",
      "993/993 [==============================] - 0s 63us/step - loss: 0.0077 - acc: 0.9980\n",
      "426/426 [==============================] - 0s 112us/step\n",
      "Score on unseen data: [0.4091785943196833, 0.9272300469483568] (corresponding to) loss acc\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=1000))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(3))\n",
    "model.add(Dense(10, input_dim=1000))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_trainN, Y_trainN, epochs=10, batch_size=32)\n",
    "print('Score on unseen data:', model.evaluate(X_testN, Y_testN, batch_size=32), '(corresponding to)', *model.metrics_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So even this simple networks has an accuracy of above 90% for the malware detection :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
